# Free AI Selector

> **Intelligent AI Model Selection Platform** - Automatically choose the best free AI model based on real-time reliability metrics

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Framework](https://img.shields.io/badge/framework-AIDD--MVP-purple.svg)](.aidd/)
[![Maturity Level](https://img.shields.io/badge/maturity-Level%202%20(Development)-green.svg)](.aidd/docs/)

## ğŸ¯ What is Free AI Selector?

Free AI Selector is a **reliability-based AI routing platform** that automatically selects the best-performing free AI model for your prompts. Instead of manually trying different AI providers, the platform:

- **Monitors** real-time success rates and response times across multiple free AI providers
- **Selects** the most reliable model using the formula: `reliability_score = (success_rate Ã— 0.6) + (speed_score Ã— 0.4)`
- **Routes** your requests automatically to the best-performing provider
- **Learns** from actual usage and synthetic monitoring to improve selection accuracy

### Key Features

âœ… **Dual-Channel Access**: REST API + Telegram Bot
âœ… **Smart Selection**: Automatic model selection based on reliability metrics
âœ… **Dual Monitoring**: Real-time metrics from actual requests + hourly synthetic checks
âœ… **6 Free AI Providers**: No credit card required - Google Gemini, Groq, Cerebras, SambaNova, HuggingFace, Cloudflare
âœ… **Production-Ready**: Level 2 maturity with health checks, JSON logging, and integration tests

---

## ğŸ—ï¸ Architecture

**Improved Hybrid Approach** with HTTP-only data access and 4 microservices:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI Manager Platform                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Telegram Bot    â”‚          â”‚  Business API    â”‚            â”‚
â”‚  â”‚  (aiogram 3.x)   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  (FastAPI)       â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                              â”‚                        â”‚
â”‚         â”‚                              â”‚ HTTP Only              â”‚
â”‚         â”‚                              â–¼                        â”‚
â”‚         â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚         â”‚                      â”‚  Data API        â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  (PostgreSQL)    â”‚            â”‚
â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                        â–²                        â”‚
â”‚                                        â”‚                        â”‚
â”‚                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚                                â”‚  Health Worker   â”‚            â”‚
â”‚                                â”‚  (APScheduler)   â”‚            â”‚
â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Services

| Service | Purpose | Port | Technology |
|---------|---------|------|------------|
| **free-ai-selector-data-postgres-api** | Data layer - CRUD operations for AI models and prompt history | 8001 | FastAPI + SQLAlchemy 2.0 async |
| **free-ai-selector-business-api** | Business logic - prompt processing, model selection, AI provider integration | 8000 | FastAPI + httpx |
| **free-ai-selector-telegram-bot** | User interface for end users (Russian language) | - | Aiogram 3.13+ |
| **free-ai-selector-health-worker** | Background monitoring - hourly synthetic checks, stats updates | - | AsyncIO + APScheduler |
| **free-ai-selector-postgres** | PostgreSQL 16 database | 5432 | PostgreSQL 16 |

---

## ğŸš€ Quick Start

### Prerequisites

- Docker 24.0+
- Docker Compose 2.0+
- Git

### 1. Clone Repository

```bash
git clone https://github.com/yourusername/free-ai-selector.git
cd free-ai-selector
```

### 2. Configure Environment

```bash
cp .env.example .env
```

**Need help getting API keys?** See detailed step-by-step guide: [API Keys Setup](docs/operations/api-keys.md)

Edit `.env` and set your API keys:

```bash
# Required: AI Provider API Keys (all 100% free, no credit card required)

# Google AI Studio - https://aistudio.google.com/apikey
# Free tier: 10 RPM, 250 RPD
GOOGLE_AI_STUDIO_API_KEY=your_google_ai_studio_key_here

# Groq - https://console.groq.com/keys
# Free tier: 20 RPM, 14,400 RPD, 1,800 tokens/sec
GROQ_API_KEY=your_groq_api_key_here

# Cerebras - https://cloud.cerebras.ai/
# Free tier: 1M tokens/day, 30 RPM, 2,500+ tokens/sec
CEREBRAS_API_KEY=your_cerebras_api_key_here

# SambaNova - https://cloud.sambanova.ai/
# Free tier: 20 RPM, 430 tokens/sec
SAMBANOVA_API_KEY=your_sambanova_api_key_here

# HuggingFace - https://huggingface.co/settings/tokens
# Free tier: Rate limited inference API
HUGGINGFACE_API_KEY=your_huggingface_token_here

# Cloudflare Workers AI - https://dash.cloudflare.com/
# Free tier: 10,000 Neurons/day
CLOUDFLARE_ACCOUNT_ID=your_cloudflare_account_id_here
CLOUDFLARE_API_TOKEN=your_cloudflare_api_token_here

# Required: Telegram Bot Token
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here

# Optional: Admin user IDs (comma-separated Telegram user IDs)
BOT_ADMIN_IDS=123456789,987654321
```

### 3. Start Services

```bash
make build  # Build all Docker images
make local  # Local mode: direct access to localhost:8000/8001
```

Wait ~30 seconds for services to initialize, then verify health:

```bash
make health
```

Expected output in `local` mode:
```
âœ… PostgreSQL: Ready
âœ… Data API (http://localhost:8001/health): Healthy
âœ… Business API (http://localhost:8000/health): Healthy
```

For VPS/reverse-proxy mode use:

```bash
make vps  # Uses docker-compose.yml + docker-compose.vps.yml
```

`make up` defaults to local mode (safe for development).

### 4. Initialize Database

```bash
make migrate  # Run database migrations
make seed     # Seed with initial AI models
```

### 5. Test the Platform

#### Option A: REST API

```bash
# 1. Simple prompt (automatic model selection)
curl -X POST http://localhost:8000/api/v1/prompts/process \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Generate a short poem about AI"}'

# 2. Prompt with system instructions
curl -X POST http://localhost:8000/api/v1/prompts/process \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "List 3 benefits of AI",
    "system_prompt": "You are a helpful technical writer. Keep responses concise and factual."
  }'

# 3. Request JSON response format
curl -X POST http://localhost:8000/api/v1/prompts/process \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Generate a list of 3 programming languages with their primary use cases",
    "response_format": {"type": "json_object"}
  }'

# 4. Combined: System prompt + JSON format
curl -X POST http://localhost:8000/api/v1/prompts/process \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Analyze the pros and cons of microservices architecture",
    "system_prompt": "You are a senior software architect. Provide structured analysis.",
    "response_format": {"type": "json_object"}
  }'

# Get model statistics
curl http://localhost:8000/api/v1/models/stats
```

**Note**:
- `system_prompt` is supported by OpenAI-compatible providers (Groq, Cerebras, SambaNova)
- `response_format: {"type": "json_object"}` requests structured JSON output
- The platform automatically selects the best available model based on reliability

#### Option B: Telegram Bot

1. Open Telegram and find your bot by token
2. Send `/start` to initialize
3. Send any text message to process it with the best AI model
4. Send `/stats` to see reliability statistics

---

## ğŸ“Š How It Works

### Reliability-Based Selection Algorithm

The platform calculates a **reliability score** for each AI model:

```python
reliability_score = (success_rate Ã— 0.6) + (speed_score Ã— 0.4)
```

Where:
- **success_rate**: Percentage of successful requests (0.0 - 1.0)
- **speed_score**: Normalized response time score (0.0 - 1.0, faster = higher)

### Dual Monitoring System

1. **Real-Time Metrics** (from actual user requests):
   - Success/failure tracking
   - Response time measurement
   - Error categorization

2. **Synthetic Monitoring** (hourly background checks):
   - Health Worker sends test prompts to all providers
   - Updates availability and baseline performance metrics
   - Detects provider outages before users encounter them

---

## ğŸ”Œ Free AI Providers

All 6 providers are **100% free with NO credit card required**:

| Provider | Model | Free Tier Limits | Speed | Credit Card |
|----------|-------|------------------|-------|-------------|
| **Google Gemini** | Gemini 2.5 Flash | 10 RPM, 250 RPD | Fast | âŒ Not Required |
| **Groq** | Llama 3.3 70B Versatile | 20 RPM, 14,400 RPD | 1,800 tokens/sec | âŒ Not Required |
| **Cerebras** | Llama 3.3 70B | 1M tokens/day, 30 RPM | 2,500+ tokens/sec | âŒ Not Required |
| **SambaNova** | Meta-Llama-3.3-70B-Instruct | 20 RPM | 430 tokens/sec | âŒ Not Required |
| **HuggingFace** | Meta-Llama-3-8B-Instruct | Rate limited | Moderate | âŒ Not Required |
| **Cloudflare** | Llama 3.3 70B FP8 Fast | 10,000 Neurons/day | Fast | âŒ Not Required |

### Getting API Keys

1. **Google AI Studio**: Visit https://aistudio.google.com/apikey - instant API key generation
2. **Groq**: Sign up at https://console.groq.com/keys - instant access to ultra-fast LPU
3. **Cerebras**: Register at https://cloud.cerebras.ai/ - world's fastest AI inference
4. **SambaNova**: Create account at https://cloud.sambanova.ai/ - access to Llama 405B
5. **HuggingFace**: Get token at https://huggingface.co/settings/tokens - free inference API
6. **Cloudflare**: Dashboard at https://dash.cloudflare.com/ - need Account ID + API Token

**Note**: All providers offer instant API key generation without payment information. Simply sign up with email and start using immediately.

---

## ğŸ› ï¸ Development

### Available Commands

```bash
make help           # Show all available commands
make local          # Start local mode (ports 8000/8001)
make vps            # Start VPS/proxy mode
make up             # Start in current MODE (default: local)
make down           # Stop services
make logs           # View logs from all services
make logs-business  # View Business API logs only
make test           # Run all tests (â‰¥75% coverage required)
make lint           # Run linters (ruff, mypy, bandit)
make format         # Format code with ruff
make migrate        # Run database migrations
make shell-business # Open shell in Business API container
make db-shell       # Open PostgreSQL shell
```

### Project Structure

```
free-ai-selector/
â”œâ”€â”€ .aidd/                      # AIDD-MVP framework (git submodule)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ free-ai-selector-data-postgres-api/    # Data layer service
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ api/            # FastAPI routes
â”‚   â”‚   â”‚   â”œâ”€â”€ domain/         # Domain models
â”‚   â”‚   â”‚   â”œâ”€â”€ infrastructure/ # Database, repositories
â”‚   â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ tests/              # Unit + integration tests
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ free-ai-selector-business-api/         # Business logic service
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ application/    # Use cases
â”‚   â”‚   â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”‚   â”œâ”€â”€ infrastructure/ # HTTP clients, AI providers
â”‚   â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ free-ai-selector-telegram-bot/         # Telegram interface
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ free-ai-selector-health-worker/        # Background monitoring
â”‚       â””â”€â”€ ...
â”œâ”€â”€ shared/                     # Shared utilities (future)
â”œâ”€â”€ docker-compose.yml          # Base config (all services, no ports)
â”œâ”€â”€ docker-compose.override.yml # Local mode override (ports 8000/8001)
â”œâ”€â”€ docker-compose.vps.yml      # VPS mode override (proxy-network)
â”œâ”€â”€ Makefile                    # Development commands
â””â”€â”€ README.md                   # This file
```

### Testing

Run tests with coverage reporting:

```bash
make test
```

Level 2 maturity requires **â‰¥75% code coverage** for all services.

---

## ğŸ“– API Documentation

### Interactive Docs (Swagger / ReDoc)

ĞŸÑ€Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ñ… ÑĞµÑ€Ğ²Ğ¸ÑĞ°Ñ…:

| Ğ¡ĞµÑ€Ğ²Ğ¸Ñ | Swagger UI | ReDoc |
|--------|------------|-------|
| Business API | http://localhost:8000/docs | http://localhost:8000/redoc |
| Data API | http://localhost:8001/docs | http://localhost:8001/redoc |

### Business API (port 8000)

Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ»Ğ¾Ğ³Ğ¸ĞºĞ°, Ğ¼Ğ°Ñ€ÑˆÑ€ÑƒÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ² Ğ¸ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ AI-Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ°Ğ¼Ğ¸.

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/prompts/process` | ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ AI-Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ |
| `GET` | `/api/v1/models/stats` | Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ½Ğ°Ğ´Ñ‘Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²ÑĞµÑ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ |
| `POST` | `/api/v1/providers/test` | Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²ÑĞµ AI-Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ñ‹ |
| `GET` | `/health` | Health check (ÑĞµÑ€Ğ²Ğ¸Ñ + Data API) |
| `GET` | `/api` | Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ÑĞµÑ€Ğ²Ğ¸ÑĞµ |

**ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ endpoint** â€” `POST /api/v1/prompts/process`:

```bash
curl -X POST http://localhost:8000/api/v1/prompts/process \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Write a poem about AI",
    "system_prompt": "You are a creative writer",
    "model_id": 3,
    "response_format": {"type": "json_object"}
  }'
```

ĞÑ‚Ğ²ĞµÑ‚ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ telemetry: `attempts` (ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğº) Ğ¸ `fallback_used` (Ğ±Ñ‹Ğ» Ğ»Ğ¸ fallback).

ĞŸÑ€Ğ¸ Ğ¿ĞµÑ€ĞµĞ³Ñ€ÑƒĞ·ĞºĞµ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ **429** / **503** Ñ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ¼ `Retry-After` Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼ `ErrorResponse`.

### Data API (port 8001)

CRUD Ğ´Ğ»Ñ AI-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ². Ğ’Ğ½ÑƒÑ‚Ñ€ĞµĞ½Ğ½Ğ¸Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ â€” Ğ½Ğµ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ Ğ¸Ğ·Ğ²Ğ½Ğµ.

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/v1/models` | Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº AI-Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ (Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹: `active_only`, `available_only`, `include_recent`) |
| `GET` | `/api/v1/models/{id}` | ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ğ¾ ID |
| `POST` | `/api/v1/models` | Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ |
| `PUT` | `/api/v1/models/{id}/stats` | ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºÑƒ |
| `POST` | `/api/v1/models/{id}/increment-success` | +1 ÑƒÑĞ¿ĞµÑ… |
| `POST` | `/api/v1/models/{id}/increment-failure` | +1 Ğ¾ÑˆĞ¸Ğ±ĞºĞ° |
| `PATCH` | `/api/v1/models/{id}/active` | Ğ’ĞºĞ»/Ğ²Ñ‹ĞºĞ» Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ |
| `PATCH` | `/api/v1/models/{id}/availability` | Cooldown Ğ¿Ñ€Ğ¸ rate limit |
| `POST` | `/api/v1/history` | Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ |
| `GET` | `/api/v1/history` | ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ |
| `GET` | `/api/v1/history/user/{user_id}` | Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ |
| `GET` | `/api/v1/history/model/{model_id}` | Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ |
| `GET` | `/api/v1/history/{id}` | Ğ—Ğ°Ğ¿Ğ¸ÑÑŒ Ğ¿Ğ¾ ID |
| `GET` | `/api/v1/history/statistics/period` | ĞĞ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ·Ğ° Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´ |
| `GET` | `/health` | Health check (ÑĞµÑ€Ğ²Ğ¸Ñ + PostgreSQL) |

### ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ

| Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ |
|----------|----------|
| [docs/api/business-api.md](docs/api/business-api.md) | Business API â€” Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ endpoints, schemas, middleware, rate limiting |
| [docs/api/data-api.md](docs/api/data-api.md) | Data API â€” Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ endpoints, schemas, query parameters |
| [docs/api/errors.md](docs/api/errors.md) | ĞšĞ¾Ğ´Ñ‹ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº, `ErrorResponse` (F025), error classification, troubleshooting |
| [docs/api/examples.md](docs/api/examples.md) | 16+ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ¾Ğ² curl Ğ¸ Python client Ğ´Ğ»Ñ Ğ²ÑĞµÑ… endpoints |

### ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ API

- **ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸** Ğ¿Ğ¾ reliability score Ñ fallback Ğ¿Ñ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ñ…
- **ĞŸÑ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸** Ñ‡ĞµÑ€ĞµĞ· `model_id` Ñ fallback (F019)
- **System prompt** Ğ¸ **JSON response format** (F011-B)
- **Per-request telemetry**: `attempts`, `fallback_used` Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğµ (F023)
- **Backpressure**: HTTP 429/503 Ñ `Retry-After` Ğ¸ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼ `ErrorResponse` (F025)
- **Circuit Breaker**: Ğ°Ğ²Ñ‚Ğ¾Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ½ĞµÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¾Ğ² (F024)
- **Recent metrics**: Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¿Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼ ÑĞºĞ¾Ğ»ÑŒĞ·ÑÑ‰ĞµĞ³Ğ¾ Ğ¾ĞºĞ½Ğ° (F010)
- **Request tracing**: `X-Request-ID` / `X-Correlation-ID` headers

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Follow the project guidelines in `CLAUDE.md`
4. Ensure tests pass and coverage â‰¥75%
5. Commit your changes (`git commit -m 'feat: add amazing feature'`)
6. Push to the branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Built with [AIDD-MVP Generator](.aidd/) - AI-Driven Development framework for microservices
- Free AI providers (no credit card required):
  - [Google AI Studio](https://aistudio.google.com/) - Gemini models
  - [Groq](https://groq.com/) - Ultra-fast LPU inference
  - [Cerebras](https://cerebras.ai/) - Wafer-Scale Engine, world's fastest AI
  - [SambaNova](https://sambanova.ai/) - Llama 405B access
  - [HuggingFace](https://huggingface.co/) - Free inference API
  - [Cloudflare Workers AI](https://developers.cloudflare.com/workers-ai/) - Serverless GPU inference

---

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/free-ai-selector/issues)
- **API Keys Setup**: [API Keys Setup](docs/operations/api-keys.md) - Detailed guide for getting API keys
- **Documentation**: [CLAUDE.md](CLAUDE.md) - Project guidelines and architecture
- **Framework Guide**: [.aidd/CLAUDE.md](.aidd/CLAUDE.md) - AIDD-MVP workflow

---

**Maturity Level**: Level 2 (Development Ready) - Suitable for development teams of 2-5 developers preparing for beta launch.

For production deployment (Level 4+), see [.aidd/knowledge/architecture/](.aidd/knowledge/architecture/).
