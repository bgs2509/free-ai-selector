"""
AI Manager Platform - Telegram Bot Service

Telegram bot interface for prompt processing with AI.
Level 2 (Development Ready) maturity.
User interface in Russian.
"""

import asyncio
import logging
import os
from typing import Optional

import httpx
from aiogram import Bot, Dispatcher, F, Router
from aiogram.filters import Command
from aiogram.types import Message

# =============================================================================
# Configuration
# =============================================================================

SERVICE_NAME = "aimanager_telegram_bot"
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
BUSINESS_API_URL = os.getenv("BUSINESS_API_URL", "http://localhost:8000")
LOG_LEVEL = os.getenv("TELEGRAM_BOT_LOG_LEVEL", "INFO")
BOT_MAX_MESSAGE_LENGTH = int(os.getenv("BOT_MAX_MESSAGE_LENGTH", "4000"))

# =============================================================================
# Logging Configuration (Level 2: JSON logging)
# =============================================================================

logging.basicConfig(
    level=LOG_LEVEL,
    format='{"timestamp": "%(asctime)s", "level": "%(levelname)s", "service": "'
    + SERVICE_NAME
    + '", "message": "%(message)s"}',
    datefmt="%Y-%m-%d %H:%M:%S",
)

logger = logging.getLogger(__name__)

# =============================================================================
# HTTP Client for Business API
# =============================================================================


async def call_business_api(prompt: str) -> Optional[dict]:
    """
    Call Business API to process prompt.

    Args:
        prompt: User's prompt text

    Returns:
        Response dict with AI-generated text, or None if failed
    """
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                f"{BUSINESS_API_URL}/api/v1/prompts/process",
                json={"prompt": prompt},
            )
            response.raise_for_status()
            return response.json()

    except httpx.HTTPError as e:
        logger.error(f"Business API call failed: {str(e)}")
        return None


async def get_models_stats() -> Optional[dict]:
    """
    Get models statistics from Business API.

    Returns:
        Stats dict with models info, or None if failed
    """
    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            response = await client.get(f"{BUSINESS_API_URL}/api/v1/models/stats")
            response.raise_for_status()
            return response.json()

    except httpx.HTTPError as e:
        logger.error(f"Failed to fetch models stats: {str(e)}")
        return None


# =============================================================================
# Bot Setup
# =============================================================================

if not TELEGRAM_BOT_TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN environment variable is required")

bot = Bot(token=TELEGRAM_BOT_TOKEN)
dp = Dispatcher()
router = Router()

# =============================================================================
# Command Handlers (Russian UI)
# =============================================================================


@router.message(Command("start"))
async def cmd_start(message: Message):
    """
    Handle /start command.

    Russian: –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏ –∫—Ä–∞—Ç–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±–æ—Ç–µ.
    """
    welcome_text = """
üëã <b>–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ Free AI Selector!</b>

–Ø –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞—é –ª—É—á—à—É—é –±–µ—Å–ø–ª–∞—Ç–Ω—É—é AI –º–æ–¥–µ–ª—å –¥–ª—è –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.

<b>–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</b>
‚Ä¢ –ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –ª—é–±–æ–π —Ç–µ–∫—Å—Ç ‚Äî —è –æ–±—Ä–∞–±–æ—Ç–∞—é –µ–≥–æ —á–µ—Ä–µ–∑ —Å–∞–º—É—é –Ω–∞–¥—ë–∂–Ω—É—é AI –º–æ–¥–µ–ª—å
‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /stats –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–µ–π
‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /help –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø—Ä–∞–≤–∫–∏

<b>–ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã:</b>
‚úÖ HuggingFace
‚úÖ Replicate
‚úÖ Together.ai

–ù–∞—á–Ω–∏—Ç–µ –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å ‚Äî –ø—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Å–æ–æ–±—â–µ–Ω–∏–µ!
"""
    await message.answer(welcome_text, parse_mode="HTML")
    logger.info(f"User {message.from_user.id} started the bot")


@router.message(Command("help"))
async def cmd_help(message: Message):
    """
    Handle /help command.

    Russian: –ü–æ–¥—Ä–æ–±–Ω–∞—è —Å–ø—Ä–∞–≤–∫–∞ –æ –∫–æ–º–∞–Ω–¥–∞—Ö –∏ —Ñ—É–Ω–∫—Ü–∏—è—Ö.
    """
    help_text = """
üìö <b>–°–ø—Ä–∞–≤–∫–∞ –ø–æ Free AI Selector</b>

<b>–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:</b>
/start ‚Äî –ù–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –±–æ—Ç–æ–º
/help ‚Äî –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É
/stats ‚Äî –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º–æ–¥–µ–ª–µ–π

<b>–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–æ—Ç:</b>
1Ô∏è‚É£ –í—ã –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
2Ô∏è‚É£ –ë–æ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –ª—É—á—à—É—é AI –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏
3Ô∏è‚É£ –ó–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
4Ô∏è‚É£ –í—ã –ø–æ–ª—É—á–∞–µ—Ç–µ –æ—Ç–≤–µ—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏

<b>–§–æ—Ä–º—É–ª–∞ –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏:</b>
reliability_score = (success_rate √ó 0.6) + (speed_score √ó 0.4)

<b>–ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤:</b>
‚Ä¢ "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ –ø—Ä–æ AI"
‚Ä¢ "–û–±—ä—è—Å–Ω–∏ –∫–≤–∞–Ω—Ç–æ–≤—É—é —Ñ–∏–∑–∏–∫—É –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏"
‚Ä¢ "–°–æ–∑–¥–∞–π —Å–ø–∏—Å–æ–∫ –∏–¥–µ–π –¥–ª—è —Å—Ç–∞—Ä—Ç–∞–ø–∞"

üí° <b>–°–æ–≤–µ—Ç:</b> –ß–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–µ–µ –∑–∞–ø—Ä–æ—Å, —Ç–µ–º –ª—É—á—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç!
"""
    await message.answer(help_text, parse_mode="HTML")
    logger.info(f"User {message.from_user.id} requested help")


@router.message(Command("stats"))
async def cmd_stats(message: Message):
    """
    Handle /stats command.

    Russian: –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É AI –º–æ–¥–µ–ª–µ–π.
    """
    await message.answer("üìä –ó–∞–≥—Ä—É–∂–∞—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º–æ–¥–µ–ª–µ–π...")

    stats = await get_models_stats()

    if stats is None:
        await message.answer(
            "‚ùå <b>–û—à–∏–±–∫–∞:</b> –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            parse_mode="HTML",
        )
        return

    models = stats.get("models", [])
    total = stats.get("total_models", 0)

    if total == 0:
        await message.answer("‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.", parse_mode="HTML")
        return

    # Sort by reliability score
    models.sort(key=lambda m: m.get("reliability_score", 0), reverse=True)

    stats_text = f"üìä <b>–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ AI –º–æ–¥–µ–ª–µ–π</b> ({total} –º–æ–¥–µ–ª–µ–π)\n\n"

    for i, model in enumerate(models, 1):
        name = model.get("name", "Unknown")
        provider = model.get("provider", "Unknown")
        reliability = model.get("reliability_score", 0.0)
        is_active = model.get("is_active", False)

        status_icon = "‚úÖ" if is_active else "‚ùå"
        medal = "ü•á" if i == 1 else "ü•à" if i == 2 else "ü•â" if i == 3 else "‚Ä¢"

        stats_text += f"{medal} <b>{name}</b>\n"
        stats_text += f"   –ü—Ä–æ–≤–∞–π–¥–µ—Ä: {provider}\n"
        stats_text += f"   –ù–∞–¥—ë–∂–Ω–æ—Å—Ç—å: {reliability:.3f} {status_icon}\n\n"

    await message.answer(stats_text, parse_mode="HTML")
    logger.info(f"User {message.from_user.id} requested stats")


# =============================================================================
# Text Message Handler (Prompt Processing)
# =============================================================================


@router.message(F.text)
async def handle_text_message(message: Message):
    """
    Handle text messages (prompt processing).

    Russian: –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.
    """
    user_prompt = message.text
    user_id = str(message.from_user.id)

    logger.info(f"Processing prompt from user {user_id}: {user_prompt[:50]}...")

    # Send "typing" action
    await message.bot.send_chat_action(chat_id=message.chat.id, action="typing")

    # Limit prompt length
    if len(user_prompt) > 5000:
        await message.answer(
            "‚ùå <b>–û—à–∏–±–∫–∞:</b> –ó–∞–ø—Ä–æ—Å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π. –ú–∞–∫—Å–∏–º—É–º 5000 —Å–∏–º–≤–æ–ª–æ–≤.",
            parse_mode="HTML",
        )
        return

    # Call Business API
    response = await call_business_api(user_prompt)

    if response is None:
        await message.answer(
            "‚ùå <b>–û—à–∏–±–∫–∞:</b> –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–ø—Ä–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /help.",
            parse_mode="HTML",
        )
        return

    # Extract response data
    ai_response = response.get("response", "")
    model_name = response.get("selected_model", "Unknown")
    provider = response.get("provider", "Unknown")
    response_time = response.get("response_time_seconds", 0.0)

    # Format response message
    response_text = f"{ai_response}\n\n"
    response_text += f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
    response_text += f"ü§ñ <b>–ú–æ–¥–µ–ª—å:</b> {model_name}\n"
    response_text += f"üîß <b>–ü—Ä–æ–≤–∞–π–¥–µ—Ä:</b> {provider}\n"
    response_text += f"‚ö° <b>–í—Ä–µ–º—è:</b> {float(response_time):.2f} —Å–µ–∫"

    # Split long messages if needed
    if len(response_text) > BOT_MAX_MESSAGE_LENGTH:
        # Send AI response separately
        await message.answer(ai_response)
        # Send metadata
        metadata = f"ü§ñ <b>–ú–æ–¥–µ–ª—å:</b> {model_name}\nüîß <b>–ü—Ä–æ–≤–∞–π–¥–µ—Ä:</b> {provider}\n‚ö° <b>–í—Ä–µ–º—è:</b> {float(response_time):.2f} —Å–µ–∫"
        await message.answer(metadata, parse_mode="HTML")
    else:
        await message.answer(response_text, parse_mode="HTML")

    logger.info(
        f"Successfully processed prompt for user {user_id} "
        f"with {model_name} in {float(response_time):.2f}s"
    )


# =============================================================================
# Main Function
# =============================================================================

dp.include_router(router)


async def main():
    """
    Main bot entry point.

    Starts polling and handles graceful shutdown.
    """
    logger.info(f"Starting {SERVICE_NAME}")
    logger.info(f"Business API URL: {BUSINESS_API_URL}")

    # Verify Business API connection
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get(f"{BUSINESS_API_URL}/health")
            if response.status_code == 200:
                logger.info("Business API connection verified")
            else:
                logger.warning(f"Business API health check returned {response.status_code}")
    except Exception as e:
        logger.error(f"Business API connection failed: {str(e)}")
        logger.warning("Bot will start but may encounter errors")

    try:
        await dp.start_polling(bot)
    finally:
        await bot.session.close()
        logger.info(f"Shutting down {SERVICE_NAME}")


if __name__ == "__main__":
    asyncio.run(main())
